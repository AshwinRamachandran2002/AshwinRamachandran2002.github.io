<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Reducing Hallucinations | Ashwin Ramachandran</title> <meta name="author" content="Ashwin Ramachandran"> <meta name="description" content="A researcher, an engineer in the making "> <meta name="keywords" content="iit, LLM, iit bombay, ashwin"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ashwinramachandran2002.github.io/blog/2023/Reducing-hallucinations/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="//"><span class="font-weight-bold">Ashwin </span>Ramachandran</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/cv.pdf">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Reducing Hallucinations</h1> <p class="post-meta">June 28, 2023</p> <p class="post-tags"> <a href="//blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="introduction">Introduction</h1> <p>LLMs suffer from hallucinations. This is a problem that is being addressed by the research community. The aim of this project is to reduce hallucinations in LLMs. Today, applications use an LLM alongside a database</p> <h1 id="quivr">Quivr</h1> <h2 id="how-it-works">How it works</h2> <p>The Quivr application is a web app that was introduced as a second brain. It allows users to upload pdfs, images, etc or websites and then query the “second brain” at a later time. Users need not go through all the information again but the application answers the queries using an LLM. The application uses Langchain Document Query api to retrieve the correct source and correct chunk and supplies it to the LLM as context. The context along with the query is input to the LLM and the LLM answers appropriately.</p> <h2 id="problems-with-the-application">Problems with the application</h2> <p>I tried uploading a bunch of pdfs and asked a bunch of questions. The LLM would incorrectly use it’s hallucinations to answer the question. The hallucinations were not even close to the answer. This would imply that the context supplied to the LLM is not relevant to the query being asked. A better way to supply context is required.</p> <h1 id="colbert-model-from-stanford">COLBERT model from Stanford</h1> <p>Developed by the Stanford NLP group, Omar Khatab.</p> <h2 id="how-it-works-1">How it works</h2> <p>I noticed the COLBERT2 retriever which used late interaction to retrieve relevant context from a huge corpus given a query. The model does not convert the whole paragraph to an embedding, i.e. it does not use the final fully connected layer in transformers to obtain a single embedding, but leaves the output as a bunch of embeddings as is produced from a decoder of a transformer. All the chunks in the corpus are converted to such group of embeddings and kept aside to be used during runtime. The query when input, is processed and output as a bunch of embeddings. These embeddings are now compared against each other on a token level rather than on a sentence level, and the result noticed is greatly better than than a sentence level comparison.</p> <h2 id="applications">Applications</h2> <p>The COLBERT model was demonstrated on the wikipedia corpus. Given a sentence “When was Titanic released?” and “Titanic, a classic, was out in theatres by 2nd October.”, the model gave a high similarity score for the tokens, “released” and “out in”, “titanic” with “titanic”, “When” with “2nd October”.</p> <h1 id="the-dsp-model">The DSP model</h1> <p>Developed by the Stanford NLP group, Omar Khatab.</p> <h2 id="how-it-works-2">How it works</h2> <p>The Demonstrate Search Predict framework, combines both the COLBERT model and the LLM. The DSP model is a multihop process. The LLM tries to break the question into multiple questions. It tries to determine the information required to answer the question. The information to be acquired is posed as a question to the COLBERT2 model which fetches the relevant context. It returns the most relevant k chunks. These chunks are given to the LLM as context, the model then uses the context to either answer the question or decide to ask more questions to make a better decision.</p> <h2 id="ncert-question-answer-retriever">NCERT Question-Answer Retriever</h2> <p>The DSP framework requires a manual setting of the number of hops it has to take before arriving at an answer. I tested out the system on the NCERT Chemistry 12th standard TextBooks and asked it the questions posed to students as part of their CBSE board examination and received the correct in answer in 80 percent of the cases. Few of the questions, it failed to answer correctly since the PDF couldn’t be converted to a text format as it was a scanned copy. The equations were converted in a jumbled manner and the sections were not formatte properly. The PDFConverter used was the Langchain API. Another factor was the size of the chunk to divide the text into; I estimate the accuracy would have been better if specific sections and paragraphs were converted as one chunk instead of division on the basis of number of tokens in a chunk. I write a more detailed blog on the NCERT Question-Answer Retriever in another blog post.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="//blog/2023/NCERT-solution-retriever/">NCERT solution retriever</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="//blog/2023/A-viable-idea/">A Mini Project: A Third Party Service to Preserve Privacy in User Prompts to LLMs</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="//blog/2023/Prompt-Injection/">Prompt Injection in LLMs</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="//blog/2023/RoPE/">Investigating the Function of RoPE in context windows</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="//blog/2023/welcome-to-jekyll/">Privacy Preservation in ML</a> </li> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>